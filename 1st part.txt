import cv2
import numpy

RED_LOWER = numpy.array([170, 50, 50])
RED_UPPER = numpy.array([180, 255, 255])

GREEN_LOWER = numpy.array([40, 100, 100])
GREEN_UPPER = numpy.array([80, 255, 255])
BLUE_LOWER = numpy.array([100, 100, 100])
BLUE_UPPER = numpy.array([140, 255, 255])

# Global variables for gesture states
red_detected = False
green_detected = False
blue_detected = False
finger_positions = []


# Create a VideoCapture object to read from the camera
cap = cv2.VideoCapture(0)  # Use 0 as the argument for the default camera
# Check if the camera is opened successfully
if not cap.isOpened():
    print("Failed to open the camera")
    exit()




# Read and display frames from the camera
while True:
    # Read a frame from the camera
    ret, frame = cap.read()
    # Check if the frame was successfully read
    if not ret:
        print("Failed to read the frame")
        break
    
    
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    #Threshold the frame to get binary masks for each tape color
    red_mask = cv2.inRange(hsv, RED_LOWER, RED_UPPER)
    green_mask = cv2.inRange(hsv, GREEN_LOWER, GREEN_UPPER)
    blue_mask = cv2.inRange(hsv, BLUE_LOWER, BLUE_UPPER)

    # Find contours in the masks
    red_contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    green_contours, _ = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    blue_contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Process red tape gesture
    if len(red_contours) > 0:
        red_detected = True
        for contour in red_contours:
            # Get the bounding box of the contour
            x, y, w, h = cv2.boundingRect(contour)
            # Draw a red line on the frame
            cv2.line(frame, (x, y), (x + w, y + h), (0, 0, 255), 2) 
    # Display the frame in a window named "Camera Feed"
    cv2.imshow("Camera Feed", frame)

    # Process green tape gesture
    if len(green_contours) > 1:
        green_detected = True
        for contour in green_contours:
            # Get the center of each contour
            M = cv2.moments(contour)
            if M["m00"] > 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                finger_positions.append((cx, cy))
        if len(finger_positions) == 2:
            # Calculate the distance between two fingers
            distance = numpy.linalg.norm(numpy.array(finger_positions[0]) - numpy.array(finger_positions[1]))
            # Zoom in or out based on the distance
            if distance > 50:
                # Zoom out
                frame = cv2.resize(frame, (int(frame.shape[1] * 1.1), int(frame.shape[0] * 1.1)))
            elif distance < 30:
                # Zoom in
                frame = cv2.resize(frame, (int(frame.shape[1] * 0.9), int(frame.shape[0] * 0.9)))
    # Display the frame in a window named "Camera Feed"
    cv2.imshow("Camera Feed", frame)
      


    # Check for the 'q' key to quit the program
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the VideoCapture object and close the windows
cap.release()
cv2.destroyAllWindows()